#import "../tools.typ": *
= Part II - Simulated Annealing
<simulated-annealing>
This section details the implementation of the TSP model using the Simulated Annealing algorithm, in the #code("SASolver") class. Simulated Annealing is a metaheuristic algorithm used to find the global optimum of a function. As the number of nodes in the TSP increases, the time required by the CPLEX solver to find the optimal solution also increases significantly. For this reason, a metaheuristic algorithm can provide a good solution within a reasonable time.
== Implementation
The #code("SASolver") class is responsible for solving the TSP using the Simulated Annealing algorithm. In order to create a new instance of the solver, the user must provide the following parameters: the maximum number of iterations for each multistart, the cooling parameter, the initial temperature, the maximum number of non-improving iterations before stopping the algorithm. The algorithm is implemented in the #code("solve()") method, which takes as input the TSP instance and returns the best solution found.

The algorithm starts by generating an initial solution. Then, it iteratively generates new solutions by choosing a neighbor of the current solution and evaluating its cost. The new solution is accepted with a probability that depends on the difference in cost between the current and new solution and a temperature parameter that decreases over time. The algorithm follows a multirestart approach, meaning that it is executed multiple times with different initial solutions to improve the chances of finding a high-quality solution. It stops when the temperature reaches zero or a predefined number of iterations is reached. The best solution found across all runs is returned as the final solution.

=== Initial solution
Based on the number of iterations of multistart, different initial solutions are generated. The chosen number for the multistart is 5, so the algorithm will generate 5 different initial solutions. This approach is used to improve the chances of finding a high-quality solution. The value 5 represents a trade-off between small and large TSP instances. For smaller instances, too many multistarts would be unnecessary since the solution space is limited, and each SA run converges quickly. Conversely, for larger instances, multiple starting points help escape poor local optima. A proper tuning of the algorithmâ€™s parameters should ideally include optimizing the number of multistarts as well. However, due to time constraints, I have chosen to focus on tuning other parameters instead.

The initial solution, of the first iteration of the algorithm, is generated using the Nearest Neighbour heuristic. This heuristic uses a greedy approach: it starts from node 0 and iteratively selects the nearest unvisited node until all nodes are visited. The time complexity of this approach is $O(n^2)$. The method that is responsible for the Nearest Neighbour Initial solution is #code("initialNeighborSolution()").

The second multistart of the algorithm uses the initial generated by #code("CheapestInsertionSolution()") method: starting from a tour with two nodes ${0, 1, 0}$, the algorithm iteratively selects the unvisited node that result in the minimum addiotional cost of inserting it in the tour. The time complexity of this  implemented approach is $O(n^3)$ in the worst case.

The remaining multistarts of the algorithm use a random initial solution. The method that is responsible for the random initial solution is #code("randomize()"), of the #code("TSPSolution") class. 

This approach allows the algorithm to explore different regions of the solution space: the Nearest Neighbour heuristic and the Cheapest Insertion heuristic provide a good starting point, while the random initial solution allows the algorithm to identify different local optima. In general, as said by the professor during the lectures, no evidences attest that better solutions are obtained starting from better initial solutions, however i chose to implement this approach in order to differentiate the origianl Simulated Annealing algorithm.

Note that the two heuristics were found online searching for TSP heuristics#footnote(link("https://ocw.mit.edu/courses/1-203j-logistical-and-transportation-planning-methods-fall-2006/resources/lec16/", [_Some Important Heuristics for TSP, 2006_])), however the implementations are made by myself.

=== Neighbour generation
The neighbourhood of a solution is defined as the set of solutions that can be obtained by applying the following moves:

- 2-opt move: reverse the order of the nodes between two randomly selected nodes. It is implemented in the #code("twoOptMove()") method; in order to evaluate the cost of the new solution, an override of the #code("evaluate()") method is used: given the two selected nodes $i$ and $j$ in the sequence $< 1 dots h, i, dots, j, l, dots, 1$, the method calculates the new costs of the solution using the following formula: $ c_"new" = c_"old" - c_(h i) - c_(j l) + c_(h j) + c_(i l)$

- 3-opt move: reverse the order of the nodes between three randomly selected nodes. It is implemented in the #code("threeOptMove()") method; in order to evaluate the cost of the new solution the standard evaluation method is used: starting from the initial node 0, the method calculates the cost of the new solution by summing the costs of the edges between the nodes in the sequence.

- swap move: swap the position of two randomly selected nodes. It is implemented in the #code("swapMove()") method; in order to evaluate the cost of the new solution the standard evaluation method is used, as for the 3-opt move.

At each iteration, one of the moves is selected at random and applied to the current solution to produce a neighboring solution. The method responsible for generating the new solution is #code("generateNeighbor()"). The moves have different probabilities of being selected: the distribution is based on the effectiveness of the 2-opt move in improving solutions, while the 3-opt and swap moves enhance exploration by escaping local optima. For large TSP instances, the 3-opt and swap moves are particularly useful, as they facilitate greater diversification in the solution space, while the 2-opt move is more effective for small instances. The probabilities of selecting the moves are defined in the #code("generateNeighbor()") method. Due to time constraints, I chose to set the probability of selecting the swap move to 0.4 and to fine tune the probabilities of selecting the 2-opt and 3-opt moves.

=== Cooling schedule
The temperature parameter is used to control the acceptance of new solutions. The temperature decreases over time according to a cooling parameter. The cooling schedule is th original one proposed by Kirkpatrick (1983): $T_(k+1) = alpha * T_k$, where $T_k$ is the temperature at iteration $k$ and $alpha$ is the cooling parameter. The temperature is initialized to a high value and decreases gradually to zero. The temperature is decreased at the end of each iteration.

=== Stopping criteria
The algorithm stops when a predefined number of iterations is reached, depending on the problem size.

== Parameters tuning
<Parameters-tuning>
The Simulated Annealing algorithm has several parameters that can be tuned to improve its performance. 

As said before in the section #fig("instances-gen", "2. Instances generator"), the training set is composed of 66% of the generated instances, while the remaining 33% is used for testing. The training set is used to find the best parameters for the Simulated Annealing algorithm. For each problem size, instances from 1 to 6 are used for training, while instances from 7 to 9 are used for testing. The algorithm is executed five times for each instance and the results are reported in different tables. 

In general, the goal was to find the best parameters for the Simulated Annealing algorithm that would allow it to find a solution closer to the optimal one in a reasonable amount of time. 

The parameters that are tuned are:
- $N_(m a x)$: the maximum number of iterations for each multistart

- $alpha$: the cooling parameter

- $T$: the initial temperature
- $N_(b a d)$: the maximum number of non-improving iterations before stopping the algorithm

- $P_(2 o p t)$: the probability of selecting the 2-opt move at each iteration

- $P_(3 o p t)$: the probability of selecting the 3-opt move at each iteration

Due to the exponential growth in the number of tests required, an exhaustive parameter search was not feasible. Instead, a set of empirical tests was performed, and the best-performing combination of parameters is reported along with the corresponding results. In general the following considerations were made:
- $N_(m a x)$: the maximum number of iterations for each multistart should be proportional to the problem size. A higher number of iterations would allow the algorithm to explore the solution space more freely, while a lower number would make the algorithm act like a local search. As the number of iterations increases, the computational time also increases.

- $alpha$: the cooling parameter influences the convergence speed of the algorithm. For smaller instances, a higher value of alpha would allow the algorithm to converge faster, while for larger instances, a lower value would be more appropriate to allow the algorithm to explore the solution space more freely.

- $T$: the initial temperature should be proportional to the problem size. A lower temperature would make the algorithm act like a local search, accepting only improving solutions, while a higher temperature would allow the algorithm to explore the solution space more freely but with a higher probability of accepting worsening solutions.
- $N_(b a d)$: the maximum number of non-improving iterations before stopping the algorithm should be proportional to the problem size. For bigger instances, an higher number of non-improving iteration would allow the algorithm to find better solutions, because the solution space is larger and the probabilities of improving solutions are lower.

- $P_(2 o p t)$: is the the best move for small instances, because it is the most effective in improving solutions, because it is the most effective in improving solutions. 
- $P_(3 o p t)$: is the best move for larger instances, because it allows the algorithm to escape local optima and explore the solution space more freely.

=== TSP size: 10 
#SAParameters_single(
  ("500", "0.99", "12", "200", "0.2", "0.4")
)

#figure(SAPerformances(
  "data/SA_10.csv",
), caption: [SA performances for TSP size 10],) <SA-performances-10>


=== TSP size: 25 
#SAParameters_single(
  ("1000", "0.96", "50", "4000", "0.15", "0.45")
)
#figure(SAPerformances(
  "data/SA_25.csv",
), caption: [SA performances for TSP size 25],) <SA-performances-25>

=== TSP size: 50 
#SAParameters_single(
  ("3000", "0.94", "100", "1000", "0.15", "0.45")
)

#figure(SAPerformances(
  "data/SA_50.csv",
), caption: [SA performances for TSP size 50],) <SA-performances-50>

=== TSP size: 75 
#SAParameters_single(
  ("15000", "0.92", "250", "5000", "0.1", "0.5")
)
#figure(SAPerformances(
  "data/SA_75.csv",
), caption: [SA performances for TSP size 75],) <SA-performances-75>
=== TSP size: 100 

#SAParameters_single(
  ("25000", "0.91", "350", "10000", "0.1" , "0.5")
)
#figure(SAPerformances(
  "data/SA_100.csv",
), caption: [SA performances for TSP size 100],) <SA-performances-100>

== Parameters Recap 
#figure(SAParameters(
  (
    "10","500", "0.99", "12", "200", "0.2", "0.4",
    "25", "1000", "0.96", "50", "4000", "0.15", "0.45",
    "50","3000", "0.94", "100", "1000", "0.15", "0.45",
    "75", "15000", "0.92", "250", "5000", "0.1", "0.5",
    "100", "25000", "0.91", "350", "10000", "0.1" , "0.5"
  )
), caption: [SA parameters for different TSP size]) <SA-parameters>




#pagebreak()